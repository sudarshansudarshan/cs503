# QR Factorization

### Matrix Decomposition and Properties

Given a matrix:
$$
\begin{bmatrix}
1 & 3 \\
2 & 4
\end{bmatrix}
\equiv
\begin{bmatrix}
\frac{1}{\sqrt{5}} & -\frac{2}{\sqrt{5}} \\
\frac{2}{\sqrt{5}} & \frac{1}{\sqrt{5}}
\end{bmatrix}
\begin{bmatrix}
\sqrt{5} & \frac{11}{\sqrt{5}} \\
0 & -\frac{2}{\sqrt{5}}
\end{bmatrix}.
$$

### Steps
1. Normalize vector $\begin{bmatrix} 1 \\ 2 \end{bmatrix}$:
   $$
   \frac{1}{\sqrt{5}}\begin{bmatrix} 1 \\ 2 \end{bmatrix} \quad \text{(Unit vector on the unit circle)}.
   $$

2. Any $2 \times 2$ matrix can be written as:
   $$
   \begin{bmatrix}
   a & b \\
   c & d
   \end{bmatrix} =
   \begin{bmatrix}
   \frac{a}{\sqrt{a^2 + c^2}} & \frac{-c}{\sqrt{a^2 + c^2}} \\
   \frac{c}{\sqrt{a^2 + c^2}} & \frac{a}{\sqrt{a^2 + c^2}}
   \end{bmatrix}
   \begin{bmatrix}
   \sqrt{a^2 + c^2} & \frac{ad - bc}{\sqrt{a^2 + c^2}} \\
   0 & \frac{\sqrt{a^2 + c^2}}{ad - bc}
   \end{bmatrix}.
   $$

### Why?

For any $n \times n$ matrix:
$$
A =
\begin{bmatrix}
\text{Norm1} & \cdots \\
0 & \text{Upper triangular matrix}
\end{bmatrix},
$$
where:
- The upper triangular matrix is always invertible.
- Upper triangular matrices lead to a unique solution of $Ax = b$.

#### Example:
$$
\begin{bmatrix}
a & b \\
0 & c
\end{bmatrix}
\begin{bmatrix}
x \\ y
\end{bmatrix}
=
\begin{bmatrix}
10 \\ 3
\end{bmatrix}.
$$
Knowing this, substitute and solve.
---
### Derivation and Non-Math Approach for Finding the Closest Plane

### Derivation:
We start with:
$$
\mathbf{A} \cdot (\mathbf{A}^T \mathbf{A})^{-1} \mathbf{A}^T \mathbf{b} = \mathbf{A} \cdot \hat{\mathbf{x}}.
$$

Substitute $\mathbf{A} = \mathbf{Q} \mathbf{R}$:
$$
\mathbf{Q} \mathbf{R} \cdot (\mathbf{Q} \mathbf{R})^T (\mathbf{Q} \mathbf{R})^{-1} \cdot (\mathbf{Q} \mathbf{R})^T \mathbf{b}.
$$

Simplify:
$$
\mathbf{Q} \mathbf{R} 
\left[
(\mathbf{R}^T \mathbf{Q}^T \mathbf{Q} \mathbf{R})^{-1}
\cdot (\mathbf{R}^T \mathbf{Q}^T)
\right] \mathbf{b}.
$$

Using properties of orthogonal matrices:
$$
\mathbf{Q} \mathbf{R} 
\left[
\mathbf{R}^{-1} (\mathbf{R}^T)^{-1} \mathbf{R}^T \mathbf{Q}^T
\right] \mathbf{b}.
$$

Simplify further:
$$
\mathbf{Q} \mathbf{R}^{-1} \mathbf{Q}^T \mathbf{b} = \mathbf{A} \hat{\mathbf{x}}.
$$

Important note:
$$
\mathbf{Q}^T \mathbf{Q} = \mathbf{I}, \quad \mathbf{Q} \mathbf{Q}^T \neq \mathbf{I}.
$$
Remember to find $\mathbf{Q}$ from $\mathbf{A}$.

---

### Non-Math Approach:
1. **Given points**, find the plane closest to all the points:
   - For example: $(\text{Physics}, \text{Mathematics}, \alpha \cdot P + \beta \cdot M + \text{Noise})$.
   - The matrix representation would be a **rank 3 matrix** due to noise.

2. **Equation of the plane**:
   $$
   px + qy + rz = 0,
   $$
   where you can toggle $p, q, r$ to fit the data.

3. Once the plane is found, estimate **Computer Science** using Physics and Mathematics as the linear combination.

---

### Key Insight:

>There are independent sources, and everything else is a **linear combination** of these sources.
---
## Estimation and Netflix Problem

### Estimation Concept:
- CS (Computer Science) may not be a **linear combination**, and could instead follow some other function.
- However, we are **estimating** it as a linear combination.

### "Mentos Zindagi" Approach:
1. Set $p, q, r$.
2. Drop perpendiculars to the plane.
3. **Sum the perpendicular lengths**.
4. The task is to **minimize this sum**.

---

## Netflix Problem:
### Task:
Predict the reviews for 20 movies based on user ratings for 80 movies.

### Setup:
- **Users** rate movies.
- **Matrix** of ratings (rows represent users, columns represent movies).
- Some entries in the matrix are missing.

### Approach:
1. Treat the **missing entry** as the value we need to predict.
2. Use the **linear combination of previous rows** to estimate the missing values.

This is similar to problems like **image restoration**.

---

### Summary:
- Use a matrix of available data to predict missing entries.
- Apply techniques like linear combinations to approximate the solution.
---
## Data Prediction and Linear Combination

### Methods for Estimation:
1. Nearest Neighbors
2. Median
3. Matrix-based approach ("something something")

---

### "Simultaneous Equations":
- Use the **same relation** on missing entries.
- Represent the missing entry as a **linear combination of previous columns**:
  $$
  x = \alpha p + \beta q + \gamma r + \delta s + \theta t.
  $$

- **Bingo!** Once computed, the missing value is filled using this linear combination.

---

### Movie Prediction:
- Similarly, a **movie** can be represented as a linear combination of **previous movies**.

For example:
$$
\text{CS} = \alpha P + \beta M,
$$
where:
- CS (Computer Science) depends on Physics ($P$) and Math ($M$).
- $\alpha$ and $\beta$ are **independent dimensions**.

---

### Key Insight:
Instead of storing the value of **CS**, **store $\alpha$ and $\beta$ instead**. This reduces redundancy and increases efficiency.

---

### Applications:
1. **Data Compression**: Represent data efficiently.
   - Example: Instagram's image compression techniques.
2. **Data Prediction**: Fill missing values in datasets.
   - Example: Netflix's movie rating prediction.
3. **Recommendation Systems**: Suggest movies based on preferences using linear combinations.

---

### User Feedback:
- Ask: "Did you really like it?"
- Ratings:
  - $9/10$: ðŸ˜Š (Positive feedback)
  - $2/10$: ðŸ˜Ÿ (Negative feedback)


