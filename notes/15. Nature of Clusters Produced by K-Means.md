# Nature of Clusters Produced by K-Means  

---

 **Introduction**  

This lecture examines the **types of clusters** formed by the **K-Means Algorithm** (Lloyd’s Algorithm) and explores the geometric structure of these clusters. Specifically, it discusses the characteristics of clusters produced when using the K-Means algorithm and how the resulting clusters align with the mathematical concept of **Voronoi regions**.

---

 **Geometric Structure of K-Means Clusters**  

**Simple Case: $$ k = 2 $$**  

1. **Two Cluster Centers**: Consider a scenario where the data is divided into two clusters with centroids (means) labeled as $$ \mu_1 $$ and $$ \mu_2 $$.
2. **Partition Condition**: For a point $$ x $$ in cluster 1, the distance from $$ x $$ to $$ \mu_1 $$ must be less than or equal to the distance to $$ \mu_2 $$. Mathematically, this condition is expressed as:

   $$
   \| x - \mu_1 \|^2 \leq \| x - \mu_2 \|^2
   $$

   Simplifying, we find that the region dividing the data between clusters 1 and 2 is defined by:

   $$
   x^T (\mu_2 - \mu_1) \leq \frac{\|\mu_2\|^2 - \|\mu_1\|^2}{2}
   $$

   This expression represents a **linear boundary** (hyperplane) between the two clusters, implying that the data space is divided into two regions by this boundary, with each region corresponding to a cluster.

**Generalization to $$ k = 3 $$**  

When three clusters $$ \mu_1 $$, $$ \mu_2 $$, and $$ \mu_3 $$ are present:

1. **Three Pairwise Boundaries**: Similar to the two-cluster case, boundaries are formed between each pair of centroids, resulting in three dividing hyperplanes.
2. **Intersection of Regions**: Points are assigned to cluster 1 if they are closer to $$ \mu_1 $$ than to $$ \mu_2 $$ or $$ \mu_3 $$. This results in regions that are intersections of the half-spaces defined by the dividing hyperplanes.

The general shape formed by this arrangement is known as a **Voronoi region**, where each cluster’s region is the space closer to its centroid than any other.

---

 **Voronoi Regions and High Dimensions**  

1. **Voronoi Definition**: A Voronoi region for a centroid $$ \mu_k $$ is the set of all points in space that are closer to $$ \mu_k $$ than to any other centroid.
2. **High-Dimensional Implication**: In higher dimensions, each cluster’s region is still defined by intersecting half-spaces. Thus, in $$ d $$-dimensional space, each cluster region resembles a higher-dimensional Voronoi cell, maintaining the concept of proximity-based partitions.

**Limitations of K-Means with Non-Linear Boundaries**  

The K-Means Algorithm can struggle with data that does not conform to Voronoi-like boundaries, such as **concentric circles**. In these cases:

1. **Linear Boundary Issue**: K-Means will only produce clusters separated by linear boundaries. As a result, it cannot accurately separate points in concentric clusters using linear boundaries alone.
2. **Kernelized K-Means**: To handle non-linear structures, **Kernel K-Means** maps data into a higher-dimensional space, allowing for more flexible, non-linear partitions.

---

 **Summary of Cluster Characteristics**  

- **Linear Separators**: K-Means clusters are separated by linear boundaries, making them ideal for data that aligns well with such partitioning.
- **Voronoi-Based Partitioning**: K-Means creates clusters that correspond to Voronoi regions, with each cluster encompassing points closer to its centroid than to any other.
- **Handling Complex Structures**: Kernel methods, such as Kernel K-Means, offer extensions to address data with non-linear separations.

---
